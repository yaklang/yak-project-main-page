---
sidebar_position: 7
---

# 基础爬虫

### 功能介绍

基础爬虫功能可以自动爬取网站链接生成网站结构树，会把爬虫爬到有效的请求响应过滤，并存到数据库中。

### 使用方法

在输入框中输入 IP / 域名 / 主机名 / URL，多目标可以逗号分隔，点击开始执行即可开始爬取

![](/img/products/yakit/base-crawler-1.png)

### 更多参数

额外参数可设置更多内容，方便爬虫更好运行。
- 参数说明：
- 设置代理：有些网站访问不到的，可以加入代理进行访问，格式为http://127.0.0.1:7890 或者 socks5://127.0.0.1:7890
- 超时时间：每个请求的最大超时时间
- 最大深度：设置爬虫的最大深度（逻辑深度，并不是级数）
- 并发量：爬虫的并发请求量（可以理解为线程数）
- 最大URL数：爬虫获取到的最大量URL（这个选项一般用来限制无限制的爬虫，一般不需要改动）
- 最大请求数：本次爬虫最多发出多少个请求？（一般用于限制爬虫行为，一般不需要改动）